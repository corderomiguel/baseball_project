---
title: Análisis estadístico sobre una base de datos de beísbol.
authors:
  - name: Miguel Cordero
    affiliation: Universidad Simón Bolívar
    location: Caracas, Venezuela
    email: 15-10326@usb.ve
  - name: Eduardo Gavazut
    affiliation: Universidad Simón Bolívar
    location: Caracas, Venezuela
    email: 13-10524@usb.ve
  - name: Luis Riera
    affiliation: Universidad Simón Bolívar
    location: Caracas, Venezuela
    email:  16-10976@usb.ve  
date: 8 de abril de 2022
abstract: >
  Este es un ejemplo de plantilla generado en RStudio para mostrar como se vería el proyecto final. Se realizarán una serie de análisis cuantitativos y cualitativos sobre una base de datos de beísbol. Se exponen los resultados y algunas conclusiones que se pueden extraer de los mismos. Cualquier error puede ser notificado para su corrección final. ESTO NO ES UN RESUMEN, se los estoy diciendo literal XD.
keywords: "Proyecto, Estadistica, Rstudio, Beisbol"
bibliography: referencias.bib
output: 
  bookdown::pdf_document2:
    template: template.tex
    keep_tex: true
  html_document: default
---
# Planteamiento del problema 

Se desea realizar un análisis estadístico completo sobre una base de datos con información sobre el rendimiento de algunos jugadores de beisbol y en particular estudiar la relación (si la hay) de los hits al bate respecto a las carreras, dobles, triples, jonrones y ponches de los jugadores. 

## Metododología

Para la realización de esta investigación se hará uso del sofware estadístico `R` en el entorno de desarrollo intergrado (IDE) `RStudio`. En este se iniciará por una descripción de los datos y variables almacenadas en el archivo fuente *Baseball.xlsx*, tales como: mínimo, media, cuantiles y desviación estándar. Para la media de las variables se obtendrá un intervalo de confianza del $95\%$. Como se desea estudiar la relación de la tasa de bateo respecto al resto de las variables, se buscará determinar la mejor distribución de probabilidad que se ajuste a esta variable. Finalmente, se estudiará la eficiencia del mejor modelo lineal de predicción que se ajuste a los datos y permita establecer si en efecto existe tal relación entre las variables y las implicaciones que tendría en las estrategias para futuros juegos de beisbol.

# Análisis de los datos

Para la realización de este proyecto se contó con una archivo de excel con la información de algunos jugadores de la Major League Beisbol o MLB, el cual se almacenó en una variable llamada `Baseball`:  

```{r include= FALSE}
# Inicializamos la librería que permite leer archivos xlsx
library(readxl)
# Asignamos a una variable la información almacenada en el archivo
Baseball <- read_excel("../../data/Baseball.xlsx")
# Mostramos las primeras 5 entradas
head(Baseball, n=5)
```

## Realizar un análisis descriptivo de los datos

### ¿Qué clase es la base de datos?

Con el comando `class`, se pudo determinar el tipo de base de datos utilizada o lo que es equivalente, la clase de la variable `Baseball`.

```{r include=FALSE}
class(Baseball)
```

El resultado que se obtuvo indica que es del tipo `tbl_df`, que es una subclase de la clase `data.frame`. `tbl_df` cumple con tener propiedades diferentes por defecto y se suele referir a ellas como `tibble`. Es una clase eficiente para trabajar con bases de datos grandes y su visualización.   

### Variables en la base de datos

```{r include=FALSE}
str(Baseball)
```

Si se desea saber que tipo de variables están almacenadas en la base de datos, se puede utilizar el comando `str`. Esta función nos indica que se cuentan con $6$ variables denominadas `X1,X2,X3,X4,X5,X6`, y distribuidas de tal manera que representan la columnas de la base de datos. Cada una de estas variables tienen $45$ valores de tipo `double` o número decimal, que representan las $45$ observaciones aleatorias (una por fila) realizadas a jugadores de la (MLB) . 

Cada variable representa la siguiente información: 

* `X1`: tasa de bateo, medido en hits por veces al bate.
* `X2`: tasa de carreras anotadas, medido en carreras anotadas por veces al bate. 
* `X3`: tasa de dobles, medido en dobles por veces al bate. 
* `X4`: tasa de triples, o los tripes por veces al bate.
* `X5`: tasa de jonrones, que son los jonrones por veces al bate.
* `X6`: tasa de ponches, medido como ponches por veces al bate. 

### Estadísticos

Para obtener los estadísticos de las seis (6) variables de esta base de datos, se inicia por guardar las $45$ observaciones en un vector que represente a cada variable. 

```{r include=FALSE}
X1<- Baseball$X1
X2<- Baseball$X2
X3<- Baseball$X3
X4<- Baseball$X4
X5<- Baseball$X5
X6<- Baseball$X6
```

Con los datos vectorizados se pueden aplicar las siguientes funciones: `mean` que permite obtener la media de los datos, `median` para obtener la mediana, `quantile` para retornar los cuantiles al $0.25\%, 0.50\%$ y $0.75\%$ de cada variable, `min` para el valor mínimo, `max` para el valor máximo, `var` para la varianza, `sd` que es para la desviación estándar, `IQR` es para el rango intercuartil y finalmente, el coeficiente de variación obtenido como `stad/media`. 

```{r appendix=TRUE, echo=FALSE}
# Función para obtener un resumen estadístico completo de cada variable
estadisticos<- function(variables){
  # Inicializamos las variables
  k<- length(variables)
  # Minimo 
  minimo <- rep(0,k)
  # Media
  media <- rep(0,k)
  # Mediana
  mediana<- rep(0,k)
  # Cuartile 1: 25%
  q1 <-rep(0,k)
  # Cuartile 3: 75%
  q3 <- rep(0,k)
  # Maximo 
  maximo <- rep(0,k)
  # Rango Intercuartile 
  ric <- rep(0,k)
  # Varianza 
  varianza <- rep(0,k)
  # Desviación estándar
  stad <-rep(0,k)
  # Coeficiente de variación
  coef_var <-  rep(0,k)
  
  for(i in 1:k){
    # Minimo 
    minimo[i] <- min(variables[,i])
    # Media
    media[i] <- mean(variables[,i])
    # Mediana
    mediana[i]<- median(variables[,i])
    # Cuartile 1: 25%
    q1[i] <- quantile(variables[,i],0.25)
    # Cuartile 3: 75%
    q3[i] <- quantile(variables[,i],0.75)
    # Maximo 
    maximo[i] <- max(variables[,i])
    # Rango Intercuartile 
    ric[i] <- IQR(variables[,i])
    # Varianza 
    varianza[i] <- var(variables[,i])
    # Desviación estándar
    stad[i] <- sd(variables[,i])
    # Coeficiente de variación
    coef_var <-  stad/media 
  }
  
  # Unimos los valores obtenidos
  estadisticos <- cbind(round(minimo, digits=4),round(q1, digits = 4),
                        round(media, digits=4), round(mediana,digits=4),
                        round(q3, digits=4), round(maximo, digits=4),
                        round(ric, digits=4),round(varianza, digits=4), 
                        round(stad, digits=4), round(coef_var, digits=4))
  # Definimos los nombres de las columnas y filas
  rownames(estadisticos) <- c("X1", "X2", "X3", "X4", "X5", "X6") 
  colnames(estadisticos) <- c("Minimo", "25%", "Media", "Mediana / 50" ,
                              "75%", "Máximo", "RIC","Varianza", 
                              "Desv. Estándar","Coef. Variación")
  # Mostramos el arreglo
  return(estadisticos)
  
}
variables <-as.data.frame(Baseball)
```


```{r resumen, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
#install.packages("kableExtra")
library(knitr)
library(kableExtra)
resumen<-estadisticos(variables)
kable(resumen,caption = "Resumen Estadístico de las variables", align="ccccccccccc",
      col.names=c("Mínimo", "25%", "Media", "Mediana (50%)" ,"75%", "Máximo", "RIC",
                              "Varianza", "Desv. Estándar","Coef. Variación")) %>%
  kable_styling(latex_options ="scale_down")
```

Los resultados pueden ser apreciados en  la tabla \@ref(tab:resumen). De estos resultados hay varios puntos que podemos detacar. La varianza de los datos es muy baja indicativo que entre los datos hay pocos valores atípicos o muy dispersos, lo que se refleja en valores mas cercanos a la media. Misma interpretación se puede extender a la desviación estándar pues es la raíz cuadrada de la varianza. 

Una consecuencia de la baja varianza es que la media y la mediana son valores muy cercanos. Esto es particularmente útil al analizar el valor del `RIC`, que toma como medida central la mediana de los datos. Es decir, nos indica donde se encuentra el $50\%$ de los datos, cuánto mas bajo es el valor del RIc menos dispersos estan los datos. 

Para un análisis mas detallado de como se relacionan las variables entre sí, podemos analizar los histogramas junto a los gráficos de cajas y bigotes. 

\vspace{10mm}

### Diagramas e histograma de los datos por cada variable


```{r boxplots, echo=FALSE, fig.cap="Histograma y gráfico de cajas para las variables", fig.width=7,fig.asp=2, fig.pos="h!"}
par(mfrow=c(6,2))

hist(X1, main = "Histograma variable X1", ylab = "Frecuencia", xlab = "X1: Hits al bate", 
   col="Yellow")
boxplot(X1, main = "Gráfico de Cajas variable X1", ylab="X1: Hits por veces al bate", 
        col="Brown ")

hist(X2, main = "Histograma de la variable X2", ylab = "Frecuencia", 
     xlab = "X2: Carreras anotadas por veces al bate", col="darkorange")

boxplot(X2, main = "Gráfico de Cajas variable X2", 
      ylab="X2: Carreras por veces al bate", col="darkblue")

hist(X3, main = "Histograma de la variable X3", ylab= "Frecuencia", 
     xlab= "X3: Dobles por veces al bate", col="green")
boxplot(X3, main = "X3: Dobles por veces al bate", ylab = "Frecuencia", col = "red")

#par(mfrow=c(3,2))
hist(X4, main="Histograma de la variable X4", ylab ="Frecuencia", xlab="X4: Triples por veces al bate", 
     col ="limegreen")
boxplot(X4, main = "Triples por veces al bate", ylab = "Frecuencia", col = "green3")

hist(X5, main = "Histograma de la variable X5", ylab = "Frecuencia", xlab = "X5: Jonrones por veces al bate", 
     col="Yellow")
boxplot(X5, main = "Gráfico de Cajas variable X5",ylab="X5: Jonrones por veces al bate ", col="Brown ")

hist(X6, main = "Histograma de la variable X6", ylab = "Frecuencia", xlab = "X6: Ponches por veces al bate", 
     col="darkorange")
boxplot(X6, main = "Gráfico de Cajas variable X6", 
        ylab="X6: Ponches por veces al bate", col="darkblue")
```

De la figura \@ref(fig:boxplots) y la figura \@ref(fig:boxplots2), podemos establecer: para la variable `X1`, que los valores máximos de los datos se obtienen luego de la media, pero el mayor volumen de ellos se encuentra antes como bien se observa en el diagrama de caja que permite confirmar, además, la ausencia de datos atípicos. Para la variable `X2`,  se puede comprobar que  ver simetría de los datos que se infería de la tabla \@ref(tab:resumem), particularmente respecto al valor $0.15$ que coincide a su vez con la media de los datos. El diagrama de caja permite confirmar la ausencia de los valores atípicos.  

Por su parte, para la variable `X3` y `X4`, Vemos que en general, ambos diagramas de caja son bastante parecidos, con la única diferencia siendo que el de triples está $0.03$ puntos corrido hacia arriba y los datos desde el primer cuartil hasta la mediana están muchos más dispersos. Otra diferencia es que el diagrama de cajas para los triples no cuenta con datos atípicos, en cambio los dobles si, que corresponde a $0.3$. Todo esto hace que el diagrama de los triples sea casi simétrico, y el de los dobles sea más chato entre el valor mínimo y la mediana, en comparación con lo que tenemos entre la mediana y el máximo valor.

De la gráfica para la variable `X5` podemos ver como a medida que nos vamos acercando a $1$ , la frecuencia de jonrones decae rapidamente, mientras que al incio es muy alta. De la gráfica para la variable `X6` podemos ver que la mayoria de los jugadores se ponchan menos de un $15\%$ de las veces que estan al bate.

## Intervalo de confianza para la media de las variables

```{r echo=FALSE}
# Primero, calculemos el intervalo de confianza para cada variable, y guardemos los límites
# superiores e inferiores en un data.frame, al igual que los promedios. Esto con el objetivo
# de hacer una visualización en el siguiente bloque de código
intConf<- function(variables, level){
  k<- length(variables)
  li<- rep(0,k)
  ls<- rep(0,k)
  confi<- c(0)
  for(i in 1:k){
    confi<-t.test(variables[,i],conf.level=level)$conf.int
    li[i]<-confi[1]
    ls[i]<-confi[2]
  }
  promedios <- colMeans(Baseball)
  Variables <- c("Tasa de bateo", "Carreras anotadas", "Dobles", "Triples", "Jonrones", "Ponches")
  dt <- data.frame(Limite_Inferior=li,Promedios=promedios,  Limite_Superior=ls, row.names = Variables)
  
  return(dt)
}

intervalos<-intConf(variables, 0.97)
```

Con el uso de la función `t.test()` se puede encontrar el intervalo de confianza con una significancia de $0.03$ o $97\%$ de confianza para las variables estudiadas. Los resultados de aplicar esta función, se pueden visualizar en la tabla \@ref(tab:intervals). 

```{r intervals, echo=FALSE, message=TRUE, warning=TRUE}

kable(intervalos, caption = "Intervalos del 97% de confianza para las medias de las variables", align="ccc", digits=4,
      col.names=c( "Limite inferior", "Promedio", "Limite Superior")) %>%
  kable_styling(latex_options ="scale_down")
```


Vemos que para cada variable, los intervalos de confianza son

\begin{enumerate}
  \item Tasa de bateo (hits/veces al bate): $(0.2657556, 0.2951778)$.
  \item Carreras anotadas (por veces al bate): $(0.1368441, 0.1649337)$.
  \item Dobles (por veces al bate): $(0.04286130, 0.04984981)$.
  \item Triples (por veces al bate): $(0.008962058, 0.013615720)$.
  \item Jonrones (por veces al bate): $(0.01682441, 0.03170892)$.
  \item Ponches (por veces al bate): $(0.08325165, 0.12541501)$.
\end{enumerate}

Ahora, para visualizar un poco mejor estos intervalos, pasemos a graficarlos con ayuda de la librería ggplot2:

```{r fig.cap="Representación gráfica de los intervalos", echo=FALSE, message=FALSE, warning=FALSE}

library(ggplot2)

promedios <- colMeans(Baseball)
Variables <- c("Tasa de bateo", "Carreras anotadas", "Dobles", "Triples", "Jonrones", "Ponches")
  
conf_graf <- ggplot(intervalos) +
  geom_errorbar(aes(x=Variables, ymin=Limite_Inferior, ymax=Limite_Superior), width=0.4, color="blue") +
  geom_point(aes(x=Variables, y=promedios), color="blue")

conf_graf
```

Vemos que en general, los intervalos de confianza más estrechos son los de dobles y triples, lo que nos indica que en general, con una probabilidad del 97%, podemos asegurar que los jugadores de la MLB tendrán un promedio de triples y dobles que puede ser estimado con bastante certeza, pero vemos que las carreras anotadas, los ponches y la tasa de bateo tienen un intervalo de confianza mucho más grande, por lo que no podemos asegurar que el promedio será estimado de forma tan certera.


## Promedio de bateo 

Se desea probar con un nivel de significancia de $\alpha=0.05$, que el promedio de bateo es inferior a $0.300$. 

Como hipótesis nula $H_{0}$, supongamos que la media de bateo, $\overline{X1}$, es igual a $0.3$. Y como hipótesis alternativa, $H_{a}$, que el promedio de bateo es superior a $0.3$, $\overline{X1}>0.3$. 

Suponiendo que los datos presentan una distribución normal, podemos aplicar el comando `t.test`.

```{r eval=FALSE, echo=FALSE}
t.test(X1, alternative = "greater", mu=0.3, conf.level = 0.95)
```

Con este función, se obtuvo que el valor para el estadístico $t$ es $-23.811$, con $44$ grados libertad. Como el $p-valor$ es bastante alto, de hecho es igual $0,9976$ (que representa un $99.76\%$), se cumple que $\alpha=0.05<99.76$ y por lo tanto la hipótesis alternativa se rechaza, mas aún, se rechaza para todo nivel de significancia porque se necesita un valor para $\alpha$ más alto que el $p-valor$ para rechazar la hipótesis nula.

Se afirma entonces, con total seguridad, que la tasa de bateo es inferior a $0.300$. 


## Comparación entre las tasas de ponches y las de jonrones

Queremos extraer la tasa de jonrones y de ponches al bate, estas variables corresponden a X5 y X6, respectivamente, entonces extraigámoslas de la base de datos

```{r include=FALSE}
jonrones <- Baseball$X5
ponches <- Baseball$X6
```

Ahora, como no tenemos conocimiento acerca de las varianzas poblacionales, usaremos el test de Welch tal y como es explicado en Heumann, Schomaker (2017) para comparar las medias. En este caso, haremos una prueba de hipótesis, donde tomaremos como hipótesis

$$
H_0 : \mu_{\operatorname{jonrones}} - \mu_{\operatorname{ponches}} = 0 \text{ vs. } H_a : \mu_{\operatorname{jonrones}} - \mu_{\operatorname{ponches}} \neq 0
$$

es decir, queremos determinar si las tasas de jonrones y ponches son distintas. Ahora, usemos el `t.test()` para determinar cuál de estas hipótesis es aceptada:

```{r echo=FALSE}
t.test(jonrones, ponches, alternative='two.sided')
```

Vemos que el $\operatorname{p-valor}$ es extremadamente pequeño, mucho más que el $\alpha = 0.01$ que es razonable utilizar para nuestra prueba de hipótesis. Adicionalmente, vemos que en el intervalo de confianza no se incluye el cero. Otra cosa que podemos hacer es evaluar el estadístico de prueba con el comando `qt()` (vemos por lo anterior que $dt = 55$ y $\alpha = 0.05$):

```{r}
qt(0.975, 55)
```

Como $t=-8$, vemos que el estadístico cae en la región de rechazo (porque es de cola doble).

Para cualquiera de estos casos, podemos concluir que la hipótesis nula se rechaza, es decir que hay suficiente evidencia para creer que $\mu_{\operatorname{jonrones}} - \mu_{\operatorname{ponches}} \neq 0$, además, como el intervalo de confianza es negativo, concluimos que $\mu_{\operatorname{ponches}} > \mu_{\operatorname{jonrones}}$ con un nivel de confianza del $95\%$.

## Gráfico de dispersión y matrix de correlación 


```{r echo=FALSE, fig.cap="Gráfico de Dispersión", fig.pos="h!"}
variables <- rbind( X1, X2, X3, X4, X5, X6)
nombres <- c("Tasa de Bateo", "Tasa de Carreras Anotadas", "Tasa de Dobles", 
             "Tasa de Triples", "Tasa de Jonrones", "Tasa de ponches")
simbolos <- c("X1", "X2", "X3", "X4", "X5", "X6")
par(mfrow=c(2,3))
for( i in 1:6){
  plot(variables[i,], main=nombres[i], xlab="", ylab=simbolos[i])
}

```


## Matriz de Correlación: 

```{r echo=FALSE, fig.cap="Matrix de correlación", fig.pos="h!"}
## Codigo de R-coder https://r-coder.com/grafico-correlacion-r/
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr")
    on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    Cor <- abs(cor(x, y)) # Elimina la función abs si lo prefieres
    txt <- paste0(prefix, format(c(Cor, 0.123456789), digits = digits)[1])
    if(missing(cex.cor)) {
        cex.cor <- 0.4 / strwidth(txt)
    }
    text(0.5, 0.5, txt,
         cex = 1 + cex.cor * Cor) # Escala el texto al nivel de correlación
}
grupos<- Baseball[1,]
# Dibujamos la matriz de correlación
pairs(Baseball,
      upper.panel = panel.cor,    # Panel de correlación
      col = c("Orange","Brown"),            # Colores de los puntos
      bg = c("Orange","Brown"),            # Colores de los puntos
      pch = 21,                   # Símbolo pch
      main = "Matriz de Correlación de las variables",  # Titulo
      cex.labels = NULL,        # Tamaño del texto de la diagonal
      font.labels = 1          # Estilo de fuente del texto de la diagonal
)
```



\newpage

# Referencias 

Codigos utilizados en este informe:

```{r ref.label = knitr::all_labels(appendix == TRUE), echo=TRUE, eval=FALSE}

```